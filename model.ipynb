{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Object Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a utiliser python 3.7\n",
    "\n",
    "# Installer Keras\n",
    "!python -m pip install Keras==2.2.4 Keras-Applications==1.0.8 Keras-Preprocessing==1.1.2\n",
    "\n",
    "# Installer TensorFlow\n",
    "!python -m pip install tensorflow==1.15.0 tensorflow-estimator==1.15.1 tensorboard==1.15.0\n",
    "\n",
    "# Installer Scikit-Image (en installant également ses dépendances courantes)\n",
    "!python -m pip install scikit-image==0.16.2\n",
    "\n",
    "# Autres dépendances essentielles\n",
    "!python -m pip install numpy==1.21.6 scipy==1.7.3 pandas==1.0.3 matplotlib==3.5.3 Pillow==9.5.0\n",
    "\n",
    "# Packages supplémentaires pour la manipulation et l'affichage des données\n",
    "!python -m pip install seaborn==0.11.2 tqdm==4.66.6 requests==2.31.0\n",
    "\n",
    "# Pour la manipulation JSON et les fichiers de labels (Labelme2COCO, Pybboxes)\n",
    "!python -m pip install jsonschema==4.17.3 labelme2coco==0.2.6 pybboxes==0.1.6\n",
    "\n",
    "# Installations pour des modules auxiliaires comme l'interface utilisateur et le client Jupyter\n",
    "!python -m pip install jupyter-client==7.4.9 jupyter-core==4.12.0 nest-asyncio==1.6.0\n",
    "\n",
    "# Packages pour le développement d'algorithmes et calculs mathématiques avancés\n",
    "!python -m pip install absl-py==2.1.0 cloudpickle==2.2.1 dask==2022.2.0\n",
    "\n",
    "# Packages de manipulation d'images et de fichiers multimédia\n",
    "!python -m pip install opencv-python==3.4.13.47 imageio==2.10.4\n",
    "\n",
    "# Installations pour les réseaux de neurones et autres applications IA\n",
    "!python -m pip install torch==1.13.1 sahi==0.11.18\n",
    "\n",
    "# Installations pour gérer les fichiers et le système\n",
    "!python -m pip install fsspec==2023.1.0 importlib-resources==5.12.0 importlib-metadata==6.7.0\n",
    "\n",
    "# Installations pour la manipulation de JSON et la gestion des chemins de fichiers\n",
    "!python -m pip install attrs==24.2.0 pyparsing==3.1.4 typing-extensions==4.7.1\n",
    "\n",
    "# Gestion des demandes réseau et de l'interface utilisateur\n",
    "!python -m pip install urllib3==1.26.16 termcolor==2.3.0 colorama==0.4.6\n",
    "\n",
    "# Autres utilitaires importants pour le système et les structures de données\n",
    "!python -m pip install setuptools==68.0.0 wheel==0.42.0 wrapt==1.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prépapration des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_annotations(dataset_dir, subset):\n",
    "    \"\"\"\n",
    "    Corrige les annotations pour que tous les polygones soient valides :\n",
    "    - Limite les coordonnées des points des polygones aux dimensions de l'image.\n",
    "    - Supprime les polygones invalides (moins de 3 points).\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): Répertoire contenant les données.\n",
    "        subset (str): Sous-ensemble à traiter (\"train\" ou \"val\").\n",
    "    \"\"\"\n",
    "    # Répertoire du sous-ensemble (train ou val)\n",
    "    subset_dir = os.path.join(dataset_dir, subset)\n",
    "    \n",
    "    # Lister et recuperer tous les fichiers JSON dans le répertoire\n",
    "    json_files = [f for f in os.listdir(subset_dir) if f.endswith(\".json\")]\n",
    "\n",
    "    # Parcourir chaque fichier JSON\n",
    "    for json_file in json_files:\n",
    "        json_path = os.path.join(subset_dir, json_file)  # Chemin complet du fichier JSON\n",
    "\n",
    "        # Charger les annotations du fichier\n",
    "        with open(json_path, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "\n",
    "        # Charger l'image associée pour obtenir ses dimensions\n",
    "        image_path = os.path.join(subset_dir, annotations['imagePath'])\n",
    "        image = plt.imread(image_path)  # Charger l'image\n",
    "        height, width = image.shape[:2]  # Récupérer la hauteur et la largeur de l'image\n",
    "\n",
    "        # Liste pour stocker les formes valides\n",
    "        valid_shapes = []\n",
    "\n",
    "        # Parcourir chaque polygone dans les annotations\n",
    "        for shape in annotations['shapes']:\n",
    "            points = shape['points']  # Points du polygone\n",
    "            corrected_points = []\n",
    "\n",
    "            # Corriger chaque point du polygone\n",
    "            for x, y in points:\n",
    "                # Limiter les coordonnées à l'intérieur des dimensions de l'image\n",
    "                corrected_x = max(0, min(width - 1, x))  # x dans [0, width-1]\n",
    "                corrected_y = max(0, min(height - 1, y))  # y dans [0, height-1]\n",
    "                corrected_points.append([corrected_x, corrected_y])\n",
    "\n",
    "            # Vérifier si le polygone corrigé est valide (au moins 3 points)\n",
    "            if len(corrected_points) >= 3:\n",
    "                shape['points'] = corrected_points  # Mettre à jour les points corrigés\n",
    "                valid_shapes.append(shape)  # Ajouter la forme corrigée à la liste des formes valides\n",
    "\n",
    "        # Mettre à jour les annotations avec uniquement les polygones valides\n",
    "        annotations['shapes'] = valid_shapes\n",
    "\n",
    "        # Sauvegarder les annotations corrigées dans le fichier JSON\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(annotations, f, indent=4)  # Sauvegarde avec un format JSON lisible\n",
    "\n",
    "# Appliquer le prétraitement sur les ensembles d'entraînement et de validation\n",
    "dataset_dir = 'data_t'\n",
    "preprocess_annotations(dataset_dir, 'train')  # Prétraiter les annotations d'entraînement\n",
    "preprocess_annotations(dataset_dir, 'val')  # Prétraiter les annotations de validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import imgaug\n",
    "import tensorflow as tf\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Configuration du logger pour enregistrer les erreurs dans un fichier log\n",
    "logging.basicConfig(filename=\"training_errors.log\", level=logging.ERROR)\n",
    "\n",
    "# Configuration personnalisée pour Mask R-CNN\n",
    "class FlowerConfig(Config):\n",
    "    NAME = \"flower_tulip\"  # Nom du modele \n",
    "    IMAGES_PER_GPU = 3  # Nombre d'images par GPU pendant l'entraînement\n",
    "    NUM_CLASSES = 1 + 2  # Fond(background) + 2 classes : Tulipe et Non-Tulipe\n",
    "    STEPS_PER_EPOCH = 53  # Nombre de pas (batches) par époque\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8  # Seuil minimum pour considérer une détection valide\n",
    "\n",
    "# Définition d'une classe pour charger et préparer le dataset\n",
    "class FlowerDataset(utils.Dataset):\n",
    "    def load_flowers(self, dataset_dir, subset):\n",
    "        \"\"\"\n",
    "        Charger les annotations et images pour un sous-ensemble (train ou val).\n",
    "        \"\"\"\n",
    "        # Ajouter les classes au dataset\n",
    "        self.add_class(\"flower\", 1, \"tulipe\")  # Classe pour les tulipes\n",
    "        self.add_class(\"flower\", 2, \"non_tulipe\")  # Classe pour les autres fleurs\n",
    "\n",
    "        # Vérifier que le sous-ensemble est valide\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        # Charger les annotations (format JSON) pour chaque fichier\n",
    "        for filename in os.listdir(dataset_dir):\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_path = os.path.join(dataset_dir, filename)\n",
    "                with open(json_path) as f:\n",
    "                    annotations = json.load(f)\n",
    "                    polygons = [shape['points'] for shape in annotations['shapes']]  # Points des polygones\n",
    "                    label_name = annotations['shapes'][0]['label']  # Classe associée à l'objet\n",
    "                    label_id = 1 if label_name == \"tulipe\" else 2  # Mappe \"tulipe\" à 1 et \"non_tulipe\" à 2\n",
    "                    \n",
    "                    # Trouver le chemin de l'image associée (supporte plusieurs extensions)\n",
    "                    image_name = annotations['imagePath']\n",
    "                    image_path = None\n",
    "                    for ext in ['.png', '.jpg', '.jpeg']:\n",
    "                        potential_path = os.path.join(dataset_dir, os.path.splitext(image_name)[0] + ext)\n",
    "                        if os.path.exists(potential_path):\n",
    "                            image_path = potential_path\n",
    "                            break\n",
    "                    \n",
    "                    # Si l'image n'est pas trouvée, ignorer l'annotation\n",
    "                    if image_path is None:\n",
    "                        print(f\"Image {image_name} non trouvée pour le fichier {json_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Charger les dimensions de l'image\n",
    "                    image = plt.imread(image_path)\n",
    "                    height, width = image.shape[:2]\n",
    "\n",
    "                    # Ajouter l'image et ses métadonnées au dataset\n",
    "                    self.add_image(\n",
    "                        \"flower\",  # Nom de la source\n",
    "                        image_id=filename,  # Identifiant unique\n",
    "                        path=image_path,\n",
    "                        width=width, height=height,\n",
    "                        polygons=polygons,\n",
    "                        class_id=label_id  # Classe associée\n",
    "                    )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"\n",
    "        Charger les masques pour une image donnée.\n",
    "        \"\"\"\n",
    "        # Récupérer les informations sur l'image\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"flower\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "\n",
    "        # Initialiser un masque vide\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n",
    "        class_ids = np.array([info[\"class_id\"]] * len(info[\"polygons\"]))  # ID de la classe pour chaque masque\n",
    "\n",
    "        # Remplir le masque pour chaque polygone\n",
    "        for i, polygon in enumerate(info[\"polygons\"]):\n",
    "            polygon = np.array(polygon, dtype=int)  # Convertir en tableau NumPy (np)\n",
    "            rr, cc = polygon[:, 1].astype(int), polygon[:, 0].astype(int)  # Extraire les coordonnées\n",
    "            mask[rr, cc, i] = 1\n",
    "\n",
    "        return mask.astype(bool), class_ids\n",
    "\n",
    "# Charger et préparer le dataset pour l'entraînement et la validation\n",
    "dataset_dir = 'data_t'\n",
    "train_dataset = FlowerDataset()\n",
    "train_dataset.load_flowers(dataset_dir, \"train\")\n",
    "train_dataset.prepare()\n",
    "\n",
    "val_dataset = FlowerDataset()\n",
    "val_dataset.load_flowers(dataset_dir, \"val\")\n",
    "val_dataset.prepare()\n",
    "\n",
    "# Initialiser le modèle Mask R-CNN\n",
    "model = MaskRCNN(mode=\"training\", config=FlowerConfig(), model_dir='./logs3_epoche40_final')\n",
    "\n",
    "# Charger les poids du modèle pré-entraîné sur COCO, en excluant les couches spécifiques aux classes\n",
    "model.load_weights(\n",
    "    'mask_rcnn_coco.h5', \n",
    "    by_name=True, \n",
    "    exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"]\n",
    ")\n",
    "\n",
    "# Entraîner le modèle avec augmentation des données\n",
    "try:\n",
    "    augmentation = imgaug.augmenters.Fliplr(0.5)  # Appliquer une symétrie horizontale aléatoire à 50%\n",
    "    model.train(\n",
    "        train_dataset,  # Jeu de données d'entraînement\n",
    "        val_dataset,  # Jeu de données de validation\n",
    "        learning_rate=FlowerConfig().LEARNING_RATE,  # Taux d'apprentissage\n",
    "        epochs=40,  # Nombre d'époques\n",
    "        layers='heads',  # Entraîner uniquement les couches \"heads\" (heads layers)\n",
    "        augmentation=augmentation  # Ajouter l'augmentation des données\n",
    "    )\n",
    "except Exception as e:\n",
    "    # Enregistrer l'erreur dans un fichier log et afficher un message\n",
    "    logging.error(f\"Erreur pendant l'entraînement : {str(e)}\")\n",
    "    print(f\"Une erreur est survenue pendant l'entraînement, mais l'exécution continue : {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
