{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Object Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On a utiliser python 3.7\n",
    "\n",
    "# Installer Keras\n",
    "!python -m pip install Keras==2.2.4 Keras-Applications==1.0.8 Keras-Preprocessing==1.1.2\n",
    "\n",
    "# Installer TensorFlow\n",
    "!python -m pip install tensorflow==1.15.0 tensorflow-estimator==1.15.1 tensorboard==1.15.0\n",
    "\n",
    "# Installer Scikit-Image (en installant également ses dépendances courantes)\n",
    "!python -m pip install scikit-image==0.16.2\n",
    "\n",
    "# Autres dépendances essentielles\n",
    "!python -m pip install numpy==1.21.6 scipy==1.7.3 pandas==1.0.3 matplotlib==3.5.3 Pillow==9.5.0\n",
    "\n",
    "# Packages supplémentaires pour la manipulation et l'affichage des données\n",
    "!python -m pip install seaborn==0.11.2 tqdm==4.66.6 requests==2.31.0\n",
    "\n",
    "# Pour la manipulation JSON et les fichiers de labels (Labelme2COCO, Pybboxes)\n",
    "!python -m pip install jsonschema==4.17.3 labelme2coco==0.2.6 pybboxes==0.1.6\n",
    "\n",
    "# Installations pour des modules auxiliaires comme l'interface utilisateur et le client Jupyter\n",
    "!python -m pip install jupyter-client==7.4.9 jupyter-core==4.12.0 nest-asyncio==1.6.0\n",
    "\n",
    "# Packages pour le développement d'algorithmes et calculs mathématiques avancés\n",
    "!python -m pip install absl-py==2.1.0 cloudpickle==2.2.1 dask==2022.2.0\n",
    "\n",
    "# Packages de manipulation d'images et de fichiers multimédia\n",
    "!python -m pip install opencv-python==3.4.13.47 imageio==2.10.4\n",
    "\n",
    "# Installations pour les réseaux de neurones et autres applications IA\n",
    "!python -m pip install torch==1.13.1 sahi==0.11.18\n",
    "\n",
    "# Installations pour gérer les fichiers et le système\n",
    "!python -m pip install fsspec==2023.1.0 importlib-resources==5.12.0 importlib-metadata==6.7.0\n",
    "\n",
    "# Installations pour la manipulation de JSON et la gestion des chemins de fichiers\n",
    "!python -m pip install attrs==24.2.0 pyparsing==3.1.4 typing-extensions==4.7.1\n",
    "\n",
    "# Gestion des demandes réseau et de l'interface utilisateur\n",
    "!python -m pip install urllib3==1.26.16 termcolor==2.3.0 colorama==0.4.6\n",
    "\n",
    "# Autres utilitaires importants pour le système et les structures de données\n",
    "!python -m pip install setuptools==68.0.0 wheel==0.42.0 wrapt==1.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import imgaug\n",
    "import tensorflow as tf\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration personnalisée pour Mask R-CNN\n",
    "class FlowerConfig(Config):\n",
    "    NAME = \"flower_tulip\"\n",
    "    IMAGES_PER_GPU = 4\n",
    "    NUM_CLASSES = 1 + 2  # Background + Tulipe, Non-Tulipe\n",
    "    STEPS_PER_EPOCH = 40\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "    LEARNING_RATE = 0.001  \n",
    "\n",
    "\n",
    "# Préparer le dataset\n",
    "class FlowerDataset(utils.Dataset):\n",
    "    def load_flowers(self, dataset_dir, subset):\n",
    "        self.add_class(\"flower\", 1, \"tulipe\")\n",
    "        self.add_class(\"flower\", 2, \"non_tulipe\")\n",
    "\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        for filename in os.listdir(dataset_dir):\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_path = os.path.join(dataset_dir, filename)\n",
    "                with open(json_path) as f:\n",
    "                    annotations = json.load(f)\n",
    "                    polygons = [shape['points'] for shape in annotations['shapes']]\n",
    "                    label_name = annotations['shapes'][0]['label']\n",
    "                    label_id = 1 if label_name == \"tulipe\" else 2\n",
    "                    \n",
    "                    # Recherche du fichier image avec différentes extensions\n",
    "                    image_name = annotations['imagePath']\n",
    "                    image_path = None\n",
    "                    for ext in ['.png', '.jpg', '.jpeg']:\n",
    "                        potential_path = os.path.join(dataset_dir, os.path.splitext(image_name)[0] + ext)\n",
    "                        if os.path.exists(potential_path):\n",
    "                            image_path = potential_path\n",
    "                            break\n",
    "                    \n",
    "                    if image_path is None:\n",
    "                        print(f\"Image {image_name} non trouvée pour le fichier {json_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    image = plt.imread(image_path)\n",
    "                    height, width = image.shape[:2]\n",
    "\n",
    "                    self.add_image(\n",
    "                        \"flower\",\n",
    "                        image_id=filename,\n",
    "                        path=image_path,\n",
    "                        width=width, height=height,\n",
    "                        polygons=polygons,\n",
    "                        class_id=label_id\n",
    "                    )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"flower\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n",
    "        class_ids = np.array([info[\"class_id\"]] * len(info[\"polygons\"]))\n",
    "        for i, polygon in enumerate(info[\"polygons\"]):\n",
    "            polygon = np.array(polygon, dtype=int)  # Convertir en tableau NumPy entier\n",
    "            rr, cc = polygon[:, 1].astype(int), polygon[:, 0].astype(int)\n",
    "            mask[rr, cc, i] = 1\n",
    "        return mask.astype(np.bool), class_ids\n",
    "\n",
    "# Charger le dataset\n",
    "dataset_dir = 'data_t'\n",
    "train_dataset = FlowerDataset()\n",
    "train_dataset.load_flowers(dataset_dir, \"train\")\n",
    "train_dataset.prepare()\n",
    "\n",
    "val_dataset = FlowerDataset()\n",
    "val_dataset.load_flowers(dataset_dir, \"val\")\n",
    "val_dataset.prepare()\n",
    "\n",
    "# Initialiser le modèle\n",
    "model = MaskRCNN(mode=\"training\", config=FlowerConfig(), model_dir='./logs')\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# Entraîner le modèle\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "model.train(train_dataset, val_dataset, learning_rate=FlowerConfig().LEARNING_RATE, epochs=20, layers='heads', augmentation=augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
