{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import imgaug\n",
    "import tensorflow as tf\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.model import MaskRCNN\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration personnalisée pour Mask R-CNN\n",
    "class FlowerConfig(Config):\n",
    "    NAME = \"flower_tulip\"\n",
    "    IMAGES_PER_GPU = 4\n",
    "    NUM_CLASSES = 1 + 2  # Background + Tulipe, Non-Tulipe\n",
    "    STEPS_PER_EPOCH = 40\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8\n",
    "    LEARNING_RATE = 0.001  \n",
    "\n",
    "\n",
    "# Préparer le dataset\n",
    "class FlowerDataset(utils.Dataset):\n",
    "    def load_flowers(self, dataset_dir, subset):\n",
    "        self.add_class(\"flower\", 1, \"tulipe\")\n",
    "        self.add_class(\"flower\", 2, \"non_tulipe\")\n",
    "\n",
    "        assert subset in [\"train\", \"val\"]\n",
    "        dataset_dir = os.path.join(dataset_dir, subset)\n",
    "\n",
    "        for filename in os.listdir(dataset_dir):\n",
    "            if filename.endswith(\".json\"):\n",
    "                json_path = os.path.join(dataset_dir, filename)\n",
    "                with open(json_path) as f:\n",
    "                    annotations = json.load(f)\n",
    "                    polygons = [shape['points'] for shape in annotations['shapes']]\n",
    "                    label_name = annotations['shapes'][0]['label']\n",
    "                    label_id = 1 if label_name == \"tulipe\" else 2\n",
    "                    \n",
    "                    # Recherche du fichier image avec différentes extensions\n",
    "                    image_name = annotations['imagePath']\n",
    "                    image_path = None\n",
    "                    for ext in ['.png', '.jpg', '.jpeg']:\n",
    "                        potential_path = os.path.join(dataset_dir, os.path.splitext(image_name)[0] + ext)\n",
    "                        if os.path.exists(potential_path):\n",
    "                            image_path = potential_path\n",
    "                            break\n",
    "                    \n",
    "                    if image_path is None:\n",
    "                        print(f\"Image {image_name} non trouvée pour le fichier {json_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    image = plt.imread(image_path)\n",
    "                    height, width = image.shape[:2]\n",
    "\n",
    "                    self.add_image(\n",
    "                        \"flower\",\n",
    "                        image_id=filename,\n",
    "                        path=image_path,\n",
    "                        width=width, height=height,\n",
    "                        polygons=polygons,\n",
    "                        class_id=label_id\n",
    "                    )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        image_info = self.image_info[image_id]\n",
    "        if image_info[\"source\"] != \"flower\":\n",
    "            return super(self.__class__, self).load_mask(image_id)\n",
    "        info = self.image_info[image_id]\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], len(info[\"polygons\"])], dtype=np.uint8)\n",
    "        class_ids = np.array([info[\"class_id\"]] * len(info[\"polygons\"]))\n",
    "        for i, polygon in enumerate(info[\"polygons\"]):\n",
    "            polygon = np.array(polygon, dtype=int)  # Convertir en tableau NumPy entier\n",
    "            rr, cc = polygon[:, 1].astype(int), polygon[:, 0].astype(int)\n",
    "            mask[rr, cc, i] = 1\n",
    "        return mask.astype(np.bool), class_ids\n",
    "\n",
    "# Charger le dataset\n",
    "dataset_dir = 'data_t'\n",
    "train_dataset = FlowerDataset()\n",
    "train_dataset.load_flowers(dataset_dir, \"train\")\n",
    "train_dataset.prepare()\n",
    "\n",
    "val_dataset = FlowerDataset()\n",
    "val_dataset.load_flowers(dataset_dir, \"val\")\n",
    "val_dataset.prepare()\n",
    "\n",
    "# Initialiser le modèle\n",
    "model = MaskRCNN(mode=\"training\", config=FlowerConfig(), model_dir='./logs')\n",
    "model.load_weights('mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# Entraîner le modèle\n",
    "augmentation = imgaug.augmenters.Fliplr(0.5)\n",
    "model.train(train_dataset, val_dataset, learning_rate=FlowerConfig().LEARNING_RATE, epochs=20, layers='heads', augmentation=augmentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
